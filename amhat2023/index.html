<!DOCTYPE html>
<!--[if lt IE 7]>
<html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if IE 7]>
<html class="no-js lt-ie9 lt-ie8" lang="en"> <![endif]-->
<!--[if IE 8]>
<html class="no-js lt-ie9" lang="en"> <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en" xmlns="http://www.w3.org/1999/html"> <!--<![endif]-->
<head>
    <meta charset="utf-8">
    <title>Advances in Multi-modal Hearing Assistive Technologies (AMHAT) | 2023 IEEE ICASSP Satellite Workshop </title>
    <meta name="description" content="2020 IEEE World Congress on Computational Intelligence (WCCI)">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <link href="css/flexslider.min.css" rel="stylesheet" type="text/css" media="all"/>
    <link href="css/line-icons.min.css" rel="stylesheet" type="text/css" media="all"/>
    <link href="css/elegant-icons.min.css" rel="stylesheet" type="text/css" media="all"/>
    <link href="css/lightbox.min.css" rel="stylesheet" type="text/css" media="all"/>
    <link href="css/bootstrap.min.css" rel="stylesheet" type="text/css" media="all"/>
    <link href="css/theme-1.css" rel="stylesheet" type="text/css" media="all"/>
    <link href="css/custom.css" rel="stylesheet" type="text/css" media="all"/>
    <!--[if gte IE 9]>
    <link rel="stylesheet" type="text/css" href="css/ie9.css"/>
    <![endif]-->
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,400,300,600,700%7CRaleway:700'
          rel='stylesheet' type='text/css'>
    <script src="js/modernizr-2.6.2-respond-1.1.0.min.js"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
    <script>
        $(document).ready(function () {
            // Add smooth scrolling to all links
            $("a").on('click', function (event) {

                // Make sure this.hash has a value before overriding default behavior
                if (this.hash !== "") {
                    // Prevent default anchor click behavior
                    event.preventDefault();

                    // Store hash
                    var hash = this.hash;

                    // Using jQuery's animate() method to add smooth page scroll
                    // The optional number (800) specifies the number of milliseconds it takes to scroll to the specified area
                    $('html, body').animate({
                        scrollTop: $(hash).offset().top
                    }, 800, function () {

                        // Add hash (#) to URL when done scrolling (default click behavior)
                        window.location.hash = hash;
                    });
                } // End if
            });
        });
    </script>
    <style>
        .navfont {
            font-size: 14px !important;
        }
    </style>
</head>
<body>
<div class="loader">
    <div class="spinner">
        <div class="double-bounce1"></div>
        <div class="double-bounce2"></div>
    </div>
</div>

<div class="nav-container">
    <nav class="simple-bar top-bar">
        <div class="container">


            <div class="row nav-menu">
                <div class="col-md-2 col-sm-2 columns">
                    <h4 class='logo' style="padding-top: 10px;"><b> <a href="https://cogmhear.org/amhat2023/" target="_blank">AMHAT 2023</a></b></h4>
                </div>

                <div class="col-md-10 col-sm-10 columns text-right">
                    <ul class="menu">
                        <li><a href="index.html#about" target="_self" class="navfont">About</a></li>
                        <!-- <li><a href="committee.html" target="_self">Committee</a></li> -->
                        <!-- <li><a href="index.html#contact" target="_self">Contact</a></li> -->
                        <li><a href="index.html#submission" target="_self" class="navfont">Submission</a></li>
                        <li><a href="index.html#dates" target="_self" class="navfont">Important Dates</a></li>
                        <li><a href="index.html#program" target="_self" class="navfont">Program</a></li>
                        <li><a href="index.html#sponsor" target="_self" class="navfont">Sponsors</a></li>
                        <li><a href="content/CFP.pdf" target="_self" class="navfont">Download CFP</a></li>
                        <li><a href="https://2023.ieeeicassp.org" target="_blank" style="color: dodgerblue;" class="navfont"><b>ICASSP 2023</b></a></li>


                    </ul>


                </div>
            </div>

            <div class="mobile-toggle">
                <i class="icon icon_menu"></i>
            </div>

        </div>
    </nav>


</div>
<div class="main-container main">
    <a id="hero-slider" class="in-page-link"></a>

    <section class="hero-slider">
        <ul class="slides">
            <li class="overlay">
                <div class="background-image-holder parallax-background">
                    <img class="background-image" alt="Background Image" src="img/back2.jpg">
                </div>

                <div class="container align-vertical">
                    <div class="row">
                        <div class="col-md-12 col-sm-12">
                            <h2 class="text-white"><strong><a href="https://2023.ieeeicassp.org" style="color: white;">
                                    IEEE ICASSP 2023</a> Satellite Workshop</strong><br></h2>
                            <h2 class="text-white"><strong>Advances in Multi-modal Hearing Assistive Technologies (AMHAT)
                            </strong></h2>

                            <h3 class='text-white' style="padding-top: 10px;"><strong><br>June 10, 2023</strong></h3>
                            <h3 class='text-white' style="padding-top: 10px;"><strong>Rhodes Island, Greece
                            </strong></br></br></h3>
                            <br>
                            <a href="content/CFP.pdf" class="btn btn-primary btn-filled btn-white"><h4><b>Download CFP</b></h4></a>

                        </div>
                    </div>
                </div>

            </li>

        </ul>
        <div id="about"></div>

    </section>

    <section class="feature-selector">

        <div class="container">
            <div class="row">
                <h1 class="text-center">About AMHAT 2023</h1>
                <br>
                <div class="col-sm-12">
                    <p class="lead text-justify">
                        Hearing loss affects 1.5 billion people globally and is associated with poorer health and social
                        outcomes. Recent technological advances have enabled low-latency, high data-rate wireless
                        solutions for in-ear hearing assistive devices, which have primarily reformed the current
                        innovation direction of the hearing industry.
                        <br><br>
                        Nevertheless, even sophisticated commercial hearing aids and cochlear-implant devices are based
                        on audio-only processing, and remain ineffective in restoring speech intelligibility in
                        overwhelmingly noisy environments. Human performance in such situations is known to be dependent
                        upon input from both the aural and visual senses that are then combined by sophisticated
                        multi-level integration strategies in the brain. Due to advances in miniaturized sensors and
                        embedded low-power technology, we now have the potential to monitor not only sound but also many
                        parameters such as visuals to improve speech intelligibility. Creating future transformative
                        multimodal hearing assistive technologies that draw on cognitive principles of normal
                        (visually-assisted) hearing, raises a range of formidable technical, privacy and usability
                        challenges which need to be holistically overcome.
                        <br><br>
                        The AMHAT Workshop aims to provide an interdisciplinary forum for the wider speech signal
                        processing, artificial intelligence, wireless sensing and communications and hearing technology
                        communities to discuss the latest advances in this emerging field, and stimulate innovative
                        research directions, including future challenges and opportunities.
                    </p>
                    <br>

                </div>
                <br>

                <h3 class="text-center">Workshop Chairs</h3>
                <p class="lead text-center">
                Amir Hussain, Edinburgh Napier University, UK <br>
                Mathini Sellathurai, Heriot-Watt University, UK <br>
                Peter Bell, University of Edinburgh, UK <br>
                Katherine August, Stevens Institute of Technology, USA <br>
                </p>
                <h3 class="text-center"><br>Steering Committee Chairs</h3>
                <p class="lead text-center">
                    John Hansen, University of Texas at Dallas, USA <br>
                    Naomi Harte, Trinity College Dublin, UK <br>
                    Michael Akeroyd, University of Nottingham, UK <br>

                </p>
                <h3 class="text-center"><br>Scientific Committee</h3>
                <p class="lead text-center">
                    Yu Tsao, Academia Sinica, Taiwan<br>
                    Peter Derleth, Sonova<br>
                    Ben Milner, University of East Anglia, UK <br>
                    Jennifer Williams, University of Southampton, UK<br>
                    Emanuel Habets, University of Erlangen-Nuremberg, Germany<br>
                    Erfan Loweimi, University of Cambridge and Edinburgh Napier University, UK<br>
                    Raza Varzandeh, University of Oldenburgh, Germany<br>
                    Jesper Jesper, Aalborg University, Denmark<br>
                    Yong Xu, Tencent America, USA<br>
                    Dong Yu, Tencent AI Lab,  China<br>
                    Daniel Michelsanti, Aalborg University, Denmark<br>
                    Volker Hohmann, University of Oldenburgh, Germany<br>
                    Marc Delcroix, NTT Communication Science Laboratories, Japan<br>
                    Zheng-Hua Tan, Aalborg University, Denmark<br>
                    Harish Chandra Dubey, Microsoft, USA<br>
                    Simon Doclo, University of Oldenburgh, Germany<br>
                    Kia Dashtipour, Edinburgh Napier University<br>
                    Hsin-Min Wang, Academia Sinica, Taiwan<br>
                    Mandar Gogate, Edinburgh Napier University, UK<br>
                    Jun-Cheng Chen, Academia Sinica, Taiwan<br>
                    Adeel Ahsan, University of Wolverhampton, UK<br>
                    Alex Casson, University of Manchester, UK<br>
                    Tharm Ratnarajah, University of Edinburgh, UK<br>
                    Jen-Cheng Hou, Academia Sinica, Taiwan<br>
                    Tughrul Arslan, University of Edinburgh, UK<br>
                    Shinji Watanabe, Carnegie Mellon University<br>
                    Nima Mesgarani, Columbia University, UK<br>
                    Jesper Jensen, Aalborg University, Denmark
                </p>

            </div>
            <br>
        </div>
    </section>
    <section class="feature-selector">
        <div id="topics"></div>

        <div class="container">
            <div class="row">
                <h1 class="text-center">Topics of interest</h1>
                <br>
                <div class="col-sm-12">
                    <p class="lead text-justify">
                        The Workshop invites authors to submit papers presenting novel research related to all aspects
                        of multi-modal hearing assistive technologies, including, but not limited to the following:
                    <ol>
                        <li dir="ltr">
                            Novel explainable and privacy-preserving machine learning and
                            statistical model based approaches to multi-modal speech-in-noise
                            processing
                        </li>
                        <li dir="ltr">
                            End-to-end real-time, low-latency and energy-efficient audio-visual
                            speech enhancement and separation methods
                        </li>
                        <li dir="ltr">
                            Human auditory-inspired models of multi-modal speech perception and
                            enhancement
                        </li>
                        <li dir="ltr">
                            Internet of things (IoT), 5G/6G and wireless sensing enabled
                            approaches to multi-modal hearing assistive technologies
                        </li>
                        <li dir="ltr">
                            Multi-modal speech enhancement and separation in AR/VR environments
                        </li>
                        <li dir="ltr">
                            Innovative binaural and multi-microphone, including MEMS antenna
                            integration and multi-modal beamforming approaches
                        </li>
                        <li dir="ltr">
                            Cloud, Edge and System-on-Chip based software and hardware
                            implementations
                        </li>
                        <li dir="ltr">
                            New multi-modal speech intelligibility models for normal and
                            hearing-impaired listeners
                        </li>
                        <li dir="ltr">
                            Audio-visual speech quality and intelligibility assessment and
                            prediction techniques for multi-modal hearing assistive
                            technologies
                        </li>
                        <li dir="ltr">
                            Demonstrators of multi-modal speech-enabled hearing assistive
                            technology use cases (e.g. multi-modal listening and communication
                            devices)
                        </li>
                        <li dir="ltr">
                            Accessibility and human-centric factors in the design and
                            evaluation of multi-modal hearing assistive technology, including
                            public perceptions, ethics, standards, societal, economic and
                            political impacts
                        </li>
                        <li dir="ltr">
                            Contextual (e.g. user preference and cognitive load-aware) multi-modal hearing assistive
                            technologies
                        </li>
                        <li dir="ltr">
                            Innovative applications of multi-modal hearing assistive technologies (e.g. diagnostics,
                            therapeutics, human-robot interaction, sign-language recognition for aided communication)
                        </li>
                        <li dir="ltr">
                            Live demonstrators of multi-modal speech-enabled hearing assistive technology use cases (e.g. multi-modal cochlear implants and listening and communication devices)
                        </li>
                        <li dir="ltr">
                            Accessibility and human-centric factors in the design and evaluation of multi-modal hearing assistive technology, including public perceptions, ethics, standards, societal, economic and political impacts
                        </li>
                    </ol>
                    </p>


                </div>
            </div>
            <br>
        </div>
    </section>

    <section class="feature-selector" id="dates">

        <div class="container">
            <div class="row text-center">
                <h2>Important Dates</h2>
                <p class="lead text-center">
                    Workshop Paper Submission Deadline:  5 March 2023 <s>24 February 2023</s><br>
                    Workshop Paper Acceptance Notification: 14 April 2023<br>
                    Workshop Camera Ready Paper Deadline: 28 April 2023
                    <br>

                    All deadlines are 11:59PM UTC-12:00 ("anywhere on Earth").
                </p>

            </div>
            <br>
        </div>
    </section>
    <section class="feature-selector" id="submission">

        <div class="container">
            <div class="container">
                <div ><br>
                    <div class="row">
                        <div class="col-sm-12 text-center">

                            <h2>Paper Submission Guidelines</h2><br><br>
                            <p class="lead">
                                The AMHAT workshop accepts both <b>short (2 pages)</b> and <b>long paper (4 pages)</b> submissions on topics as highlighted in Topics of interest. Papers may be no longer than 5 pages, including all text, figures, and references, and the 5th page may contain only references. All submissions should follow the ICASSP-2023 paper style and format (<a
                                    href="https://2023.ieeeicassp.org/paper-submission-guidelines/">https://2023.ieeeicassp.org/paper-submission-guidelines/</a>).
                                <br><br>
                                <a href="https://cmt3.research.microsoft.com/ICASSP2023/Track/38/Submission/Create" class="btn btn-primary btn-filled">Paper submission now open!</a>
                                <br><br>
                                Note: The peer-reviewing process will follow the main conference reviewing guidelines
                                and all accepted Workshop papers will be published in the IEEE Xplore Digital Library.
                                Note that, like the main conference, the AMHAT Workshop is fostering return to an
                                in-person attendance experience. Accordingly, there must be an author of each accepted
                                workshop paper presenting it in-person.
                            </p>
                        </div>

                    </div>
                </div>

            </div>

        </div>
    </section>
    <section class="feature-selector">
        <div class="container">
        <div class="row">
            <div id="program" class="col-sm-12">
                <h1 class="text-center">Keynote speakers</h1>
                <div class="image-container" style="display: flex; justify-content: center;">
                    <img style='width: 15%;' src="images/keynote/1.jpg">
                </div>
                <h3 class="text-center"><br><br>Prof Yu Tsao, Academia Sinica, Taiwan</h3>
                <p class="lead text-center"><b> <br>Towards Audio-visual Speech Enhancement in Real-World Scenarios</b></p>
                <p class="lead text-justify">
                We propose a novel audio-visual speech enhancement (AVSE) algorithm, iLAVSE, for a real-world scenario. Compared to conventional AVSE systems, iLAVSE overcomes three common issues that can occur in a real-world environment: the additional cost of processing visual data, audio-visual asynchronization, and low-quality visual data. To evaluate iLAVSE, we use a multimodal Taiwan-Mandarin speech with video dataset and compare with conventional AVSE systems. The results demonstrate that iLAVSE can effectively address the aforementioned issues and improve speech enhancement performance, making it suitable for real-world applications.
                </p>
                <div class="image-container" style="display: flex; justify-content: center;">
                <img style='width: 15%;' src="images/keynote/2.jpg">
                </div>
                <h3 class="text-center"><br><br>Dr Peter Derleth, Sonova AG</h3>
                <p class="lead text-center"><b> <br>Technological and commercial aspects of assistive hearing solutions</b></p>
                <p class="lead text-justify">
                    Assistive hearing solutions come in a variety of form factors, are designed to serve various use cases, are targeted at different user groups and distributed to the market as consumer or medical products. Each of the mentioned aspects influences if a technological/functional innovation reaches the respective market segment and gets the chance to improve the daily life of human listeners. The presentation will shed a light on existing and near future hearing aid technology and share anecdotal insights into alternative technical solutions which did not reach a high market impact despite being technically advanced.
                </p>

            </div>
        </div>
        </div>
    </section>
    <section class="feature-selector">

        <div class="row">
            <div id="sponsor" class="col-sm-12">

                <div id="sponsorBox">
                    <h1 class="text-center">Sponsors</h1>
                    <img class="sponsor" style='width: 22%;' src="images/sponsors/1.jpg">
                    <img class="sponsor" style='width: 22%;' src="images/sponsors/2.jpg">
                    <img class="sponsor" style='width: 16%;' src="images/sponsors/3.jpg">
                    <img class="sponsor" style='width: 16%;' src="images/sponsors/4.png">

                </div>

            </div>

        </div>
    </section>
</div>

<div class="footer-container">
    <footer class="details text-center" >
        © Copyright 2022 - AMHAT 2023
    </footer>
</div>

<script src="https://www.youtube.com/iframe_api"></script>
<script src="js/jquery.min.js"></script>
<script src="js/jquery.plugin.min.js"></script>
<script src="js/bootstrap.min.js"></script>
<script src="js/jquery.flexslider-min.js"></script>
<script src="js/smooth-scroll.min.js"></script>
<script src="js/skrollr.min.js"></script>
<script src="js/spectragram.min.js"></script>
<script src="js/scrollReveal.min.js"></script>
<script src="js/isotope.min.js"></script>
<script src="js/twitterFetcher_v10_min.js"></script>
<script src="js/lightbox.min.js"></script>
<script src="js/jquery.countdown.min.js"></script>
<script src="js/scripts.js"></script>
</body>
</html>
